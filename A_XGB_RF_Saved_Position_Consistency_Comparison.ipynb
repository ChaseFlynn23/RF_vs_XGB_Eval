{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed7ae50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import AA_Import_LCP_Functions as chase_lcc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea501d2",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dad0c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lccdata_folder = 'lccdata_files'\n",
    "\n",
    "# Import LCC data files for wild type protein and mutant protein\n",
    "wt_dict = chase_lcc.import_lcc_data(lccdata_folder, 'w')\n",
    "D132H_dict = chase_lcc.import_lcc_data(lccdata_folder, 'm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc13ac6a",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95184421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "def prepare_data_x(wt_dict, D132H_dict, window_size):\n",
    "    wildtype_data = wt_dict[window_size]\n",
    "    wildtype_label = np.zeros(len(wildtype_data))\n",
    "    mutant_data = D132H_dict[window_size]\n",
    "    mutant_label = np.ones(len(mutant_data))\n",
    "\n",
    "    lcc_data = np.vstack((wildtype_data, mutant_data))\n",
    "    label_data = np.hstack((wildtype_label, mutant_label))\n",
    "    lcc_data, label_data = unison_shuffled_copies(lcc_data, label_data)\n",
    "    lcc_data /= 100\n",
    "    upper_training_limit = int(len(lcc_data) * 0.8)\n",
    "    \n",
    "    # Splitting the data into training and testing sets\n",
    "    X_train, X_test = lcc_data[:upper_training_limit], lcc_data[upper_training_limit:]\n",
    "    y_train, y_test = label_data[:upper_training_limit], label_data[upper_training_limit:]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b954c40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "RF Trials:   0%|                                          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting RF Trial 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "RF Trials:  20%|██████                        | 1/5 [42:39<2:50:37, 2559.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting RF Trial 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "RF Trials:  40%|███████████▏                | 2/5 [1:24:16<2:06:07, 2522.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting RF Trial 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "RF Trials:  60%|████████████████▊           | 3/5 [2:05:46<1:23:36, 2508.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting RF Trial 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "RF Trials:  80%|████████████████████████      | 4/5 [2:47:21<41:42, 2502.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting RF Trial 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RF Trials: 100%|██████████████████████████████| 5/5 [3:28:58<00:00, 2507.62s/it]\n",
      "XGB Trials:   0%|                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting XGB Trial 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "XGB Trials:  20%|██████▌                          | 1/5 [00:24<01:36, 24.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting XGB Trial 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "XGB Trials:  40%|█████████████▏                   | 2/5 [00:47<01:11, 23.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting XGB Trial 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "XGB Trials:  60%|███████████████████▊             | 3/5 [01:11<00:47, 23.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting XGB Trial 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "XGB Trials:  80%|██████████████████████████▍      | 4/5 [01:35<00:23, 23.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting XGB Trial 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGB Trials: 100%|█████████████████████████████████| 5/5 [01:59<00:00, 23.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Consistent Positions: {(2, 9): 5, (2, 11): 5, (2, 27): 5, (2, 28): 5, (2, 29): 5, (2, 39): 5, (2, 41): 5, (3, 7): 5, (3, 8): 5, (3, 11): 5, (3, 20): 5, (3, 26): 5, (3, 27): 5, (3, 28): 5, (4, 6): 5, (4, 9): 5, (4, 10): 5, (4, 11): 5, (4, 19): 5, (4, 20): 5, (4, 23): 5, (4, 27): 5, (5, 5): 5, (5, 6): 5, (5, 7): 5, (5, 11): 5, (5, 12): 5, (5, 13): 5, (5, 18): 5, (5, 20): 5, (6, 6): 5, (6, 11): 5, (6, 12): 5, (6, 21): 5, (6, 22): 5, (6, 23): 5, (7, 6): 5, (7, 11): 5, (7, 21): 5, (8, 5): 5, (8, 9): 5, (8, 13): 5, (8, 20): 5, (8, 21): 5, (8, 23): 5, (9, 5): 5, (9, 9): 5, (9, 18): 5, (9, 19): 5, (9, 21): 5, (10, 7): 5, (10, 8): 5, (10, 18): 5, (10, 19): 5, (10, 31): 5, (11, 6): 5, (11, 7): 5, (11, 17): 5, (11, 18): 5, (11, 30): 5, (12, 6): 5, (12, 9): 5, (12, 13): 5, (12, 16): 5, (12, 17): 5, (12, 18): 5, (12, 19): 5, (12, 29): 5, (12, 30): 5, (13, 5): 5, (13, 13): 5, (13, 14): 5, (13, 15): 5, (13, 16): 5, (13, 17): 5, (13, 18): 5, (13, 29): 5, (14, 4): 5, (14, 13): 5, (14, 14): 5, (14, 15): 5, (14, 16): 5, (14, 27): 5, (15, 12): 5, (15, 13): 5, (15, 14): 5, (15, 15): 5, (16, 9): 5, (16, 10): 5, (16, 11): 5, (16, 12): 5, (16, 13): 5, (16, 14): 5, (17, 9): 5, (17, 10): 5, (17, 11): 5, (17, 12): 5, (17, 13): 5, (17, 14): 5, (18, 9): 5, (18, 10): 5, (18, 11): 5, (18, 12): 5, (18, 13): 5, (19, 6): 5, (19, 8): 5, (19, 9): 5, (19, 10): 5, (19, 11): 5, (19, 12): 5, (20, 6): 5, (20, 8): 5, (20, 9): 5, (20, 10): 5, (20, 21): 5, (21, 6): 5, (21, 7): 5, (21, 8): 5, (21, 9): 5, (21, 20): 5, (22, 5): 5, (22, 6): 5, (22, 7): 5, (22, 8): 5, (22, 9): 5, (22, 19): 5, (23, 5): 5, (23, 6): 5, (23, 8): 5, (23, 18): 5, (24, 4): 5, (24, 5): 5, (24, 6): 5, (24, 7): 5, (24, 18): 5, (25, 4): 5, (25, 5): 5, (25, 6): 5, (26, 3): 5, (26, 4): 5, (26, 5): 5, (27, 4): 5, (27, 13): 5, (28, 13): 5, (29, 5): 5, (29, 13): 5, (30, 9): 5, (30, 11): 5, (31, 9): 5, (31, 10): 5, (32, 8): 5, (32, 9): 5, (33, 7): 5, (33, 8): 5, (33, 9): 5, (34, 7): 5, (35, 6): 5, (36, 6): 5, (43, 13): 5, (44, 12): 5}\n",
      "XGBoost Consistent Positions: {(2, 21): 5, (2, 26): 5, (2, 27): 5, (2, 39): 5, (2, 40): 5, (2, 41): 5, (3, 7): 5, (3, 12): 5, (3, 20): 5, (3, 26): 5, (3, 27): 5, (4, 6): 5, (4, 12): 5, (4, 19): 5, (4, 20): 5, (5, 5): 5, (5, 6): 5, (5, 7): 5, (5, 11): 5, (5, 20): 5, (5, 25): 5, (6, 6): 5, (6, 11): 5, (6, 21): 5, (6, 22): 5, (7, 6): 5, (7, 11): 5, (7, 18): 5, (7, 21): 5, (7, 38): 5, (8, 16): 5, (8, 19): 5, (8, 20): 5, (8, 21): 5, (8, 30): 5, (9, 4): 5, (9, 9): 5, (9, 15): 5, (9, 19): 5, (9, 21): 5, (9, 30): 5, (9, 32): 5, (10, 7): 5, (10, 8): 5, (10, 18): 5, (10, 19): 5, (10, 31): 5, (11, 7): 5, (11, 17): 5, (11, 18): 5, (11, 30): 5, (12, 16): 5, (12, 19): 5, (12, 23): 5, (12, 29): 5, (13, 13): 5, (13, 16): 5, (13, 17): 5, (13, 18): 5, (13, 29): 5, (14, 13): 5, (14, 15): 5, (14, 16): 5, (14, 27): 5, (15, 12): 5, (15, 13): 5, (15, 14): 5, (15, 15): 5, (15, 27): 5, (16, 1): 5, (16, 9): 5, (16, 12): 5, (16, 14): 5, (17, 10): 5, (17, 12): 5, (17, 13): 5, (17, 14): 5, (17, 29): 5, (18, 9): 5, (18, 12): 5, (18, 13): 5, (18, 23): 5, (19, 6): 5, (19, 10): 5, (19, 15): 5, (19, 22): 5, (20, 8): 5, (20, 9): 5, (20, 10): 5, (20, 15): 5, (20, 21): 5, (21, 6): 5, (21, 7): 5, (21, 9): 5, (21, 20): 5, (21, 31): 5, (22, 6): 5, (22, 19): 5, (23, 5): 5, (23, 6): 5, (23, 18): 5, (23, 29): 5, (24, 18): 5, (24, 28): 5, (25, 4): 5, (25, 18): 5, (25, 27): 5, (26, 3): 5, (26, 13): 5, (26, 29): 5, (26, 41): 5, (27, 9): 5, (27, 13): 5, (27, 29): 5, (28, 6): 5, (28, 13): 5, (29, 9): 5, (29, 13): 5, (30, 9): 5, (30, 11): 5, (31, 10): 5, (32, 9): 5, (33, 9): 5, (34, 7): 5, (35, 6): 5, (36, 6): 5, (37, 4): 5, (37, 6): 5, (38, 3): 5, (38, 18): 5, (39, 6): 5, (40, 1): 5, (40, 27): 5, (41, 0): 5, (41, 26): 5, (42, 13): 5, (43, 13): 5, (44, 12): 5, (45, 9): 5, (46, 9): 5, (47, 9): 5, (48, 9): 5, (49, 6): 5, (49, 9): 5, (49, 18): 5, (50, 6): 5, (51, 6): 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to run trials and save feature importances\n",
    "def run_trials(n_trials, classifier, classifier_name, window_sizes, lccdata_folder):\n",
    "    consistency_counts = {}\n",
    "\n",
    "    # Wrap the outer loop with tqdm for a progress bar\n",
    "    for trial in tqdm(range(1, n_trials + 1), desc=f\"{classifier_name} Trials\"):\n",
    "        print(f\"\\nStarting {classifier_name} Trial {trial}\")\n",
    "        trial_dir = f\"{classifier_name}_Consistency_Trial_{trial}\"\n",
    "        os.makedirs(trial_dir, exist_ok=True)\n",
    "\n",
    "        for window_size in window_sizes:\n",
    "            X_train, X_test, y_train, y_test = prepare_data_x(wt_dict, D132H_dict, window_size)\n",
    "            clf = classifier()\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            # Saving feature importances\n",
    "            feature_importances = clf.feature_importances_\n",
    "            trial_filename = os.path.join(trial_dir, f\"Feature_Importance_WS_{window_size}.csv\")\n",
    "            pd.DataFrame(feature_importances).to_csv(trial_filename, index=False)\n",
    "\n",
    "            # Update consistency counts based on threshold criteria\n",
    "            threshold = 0.0285 * (68 / (70 - window_size))\n",
    "            for i, importance in enumerate(feature_importances):\n",
    "                if importance > threshold:\n",
    "                    key = (window_size, i)  # (window_size, position)\n",
    "                    if key not in consistency_counts:\n",
    "                        consistency_counts[key] = [0] * n_trials\n",
    "                    consistency_counts[key][trial - 1] = 1\n",
    "\n",
    "    return consistency_counts\n",
    "\n",
    "def assess_consistency(consistency_counts, n_trials):\n",
    "    return {key: sum(values) for key, values in consistency_counts.items() if sum(values) == n_trials}\n",
    "\n",
    "# Main execution\n",
    "window_sizes = range(2, 52)\n",
    "n_trials = 5\n",
    "\n",
    "# Run trials for RF and XGBoost\n",
    "rf_consistency_counts = run_trials(n_trials, RandomForestClassifier, 'RF', window_sizes, lccdata_folder)\n",
    "xgb_consistency_counts = run_trials(n_trials, lambda: XGBClassifier(use_label_encoder=False, eval_metric='logloss'), 'XGB', window_sizes, lccdata_folder)\n",
    "\n",
    "# Assess consistency\n",
    "rf_consistent_positions = assess_consistency(rf_consistency_counts, n_trials)\n",
    "xgb_consistent_positions = assess_consistency(xgb_consistency_counts, n_trials)\n",
    "\n",
    "print(\"RF Consistent Positions:\", rf_consistent_positions)\n",
    "print(\"XGBoost Consistent Positions:\", xgb_consistent_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6ae255d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n",
      "147\n"
     ]
    }
   ],
   "source": [
    "print(len(rf_consistent_positions))\n",
    "print(len(xgb_consistent_positions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68390db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Consistency:\n",
      "1/5 Trials: 36 positions\n",
      "2/5 Trials: 20 positions\n",
      "3/5 Trials: 17 positions\n",
      "4/5 Trials: 6 positions\n",
      "5/5 Trials: 147 positions\n",
      "RF Consistency:\n",
      "1/5 Trials: 17 positions\n",
      "2/5 Trials: 14 positions\n",
      "3/5 Trials: 14 positions\n",
      "4/5 Trials: 19 positions\n",
      "5/5 Trials: 160 positions\n"
     ]
    }
   ],
   "source": [
    "# Feature selection consistency comparison\n",
    "models = ['XGB', 'RF']\n",
    "n_trials = 5\n",
    "window_sizes = range(2, 52)\n",
    "threshold = 0.0285\n",
    "results = {model: {i: 0 for i in range(1, 6)} for model in models}\n",
    "\n",
    "def weighted_threshold(window_size):\n",
    "    return threshold * (68 / (70 - window_size))\n",
    "\n",
    "def count_positions_above_threshold(model, window_size, threshold):\n",
    "    positions_above_threshold = []\n",
    "    for trial in range(1, n_trials + 1):\n",
    "        folder_name = f'{model}_Consistency_Trial_{trial}'\n",
    "        file_name = f'Feature_Importance_WS_{window_size}.csv'\n",
    "        file_path = os.path.join(folder_name, file_name)\n",
    "        \n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_csv(file_path)\n",
    "            positions_above_threshold.append(df[df['0'] > threshold].index.tolist())\n",
    "        else:\n",
    "            # Handle missing file if necessary\n",
    "            pass\n",
    "    \n",
    "    # Count positions saved in all 5, 4, 3, 2, and 1 trials\n",
    "    all_positions = set(sum(positions_above_threshold, []))\n",
    "    for position in all_positions:\n",
    "        counts = sum(position in trial_positions for trial_positions in positions_above_threshold)\n",
    "        results[model][counts] += 1\n",
    "\n",
    "for model in models:\n",
    "    for window_size in window_sizes:\n",
    "        w_threshold = weighted_threshold(window_size)\n",
    "        count_positions_above_threshold(model, window_size, w_threshold)\n",
    "\n",
    "# Results\n",
    "for model in models:\n",
    "    print(f'{model} Consistency:')\n",
    "    for k, v in results[model].items():\n",
    "        print(f'{k}/5 Trials: {v} positions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09849923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Stability Index: 0.4018\n",
      "RF Stability Index: 0.4012\n"
     ]
    }
   ],
   "source": [
    "def calculate_stability_index(consistency_counts):\n",
    "    \"\"\"\n",
    "    Calculate the stability index based on the consistency counts for different levels.\n",
    "    \n",
    "    Args:\n",
    "    - consistency_counts (dict): A dictionary where keys are the number of trials (1 to 5)\n",
    "      a feature appears in, and values are the number of positions that appear in that many trials.\n",
    "      \n",
    "    Returns:\n",
    "    - float: The calculated stability index.\n",
    "    \"\"\"\n",
    "    # Define weights for each consistency level\n",
    "    weights = {1: 1, 2: 2, 3: 3, 4: 4, 5: 5}\n",
    "    \n",
    "    # Calculate the weighted sum of positions for each consistency level\n",
    "    weighted_sum = sum(weights[key] * count for key, count in consistency_counts.items())\n",
    "    \n",
    "    # Calculate the total possible weighted sum, assuming all positions were selected in all trials\n",
    "    max_weighted_sum = sum(weights[key] * max(consistency_counts.values()) for key in weights)\n",
    "    \n",
    "    # Calculate the stability index as the ratio of the weighted sum to the maximum possible weighted sum\n",
    "    stability_index = weighted_sum / max_weighted_sum\n",
    "    \n",
    "    return stability_index\n",
    "\n",
    "# Consistency data for XGBoost and RF\n",
    "xgb_consistency = {1: 36, 2: 20, 3: 17, 4: 6, 5: 147}\n",
    "rf_consistency = {1: 17, 2: 14, 3: 14, 4: 19, 5: 160}\n",
    "\n",
    "# Calculate stability indexes\n",
    "xgb_stability_index = calculate_stability_index(xgb_consistency)\n",
    "rf_stability_index = calculate_stability_index(rf_consistency)\n",
    "\n",
    "print(f\"XGBoost Stability Index: {xgb_stability_index:.4f}\")\n",
    "print(f\"RF Stability Index: {rf_stability_index:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99f62917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Consistency Score: 3.9204\n",
      "RF Consistency Score: 4.2991\n"
     ]
    }
   ],
   "source": [
    "def calculate_consistency_score(consistency_counts):\n",
    "    \"\"\"\n",
    "    Calculate the consistency score for feature selection across trials.\n",
    "    \n",
    "    Args:\n",
    "    - consistency_counts (dict): A dictionary where keys are the number of trials (1 to 5)\n",
    "      a feature appears in, and values are the number of positions that appear in that many trials.\n",
    "    \n",
    "    Returns:\n",
    "    - float: The calculated consistency score.\n",
    "    \"\"\"\n",
    "    # Initialize total counts and weighted sum\n",
    "    total_counts = sum(consistency_counts.values())\n",
    "    weighted_sum = sum(key * value for key, value in consistency_counts.items())\n",
    "    \n",
    "    # Calculate the consistency score as the weighted sum of positions divided by the total counts\n",
    "    consistency_score = weighted_sum / total_counts if total_counts else 0\n",
    "    \n",
    "    return consistency_score\n",
    "\n",
    "# Consistency data for XGBoost and RF\n",
    "xgb_consistency = {1: 36, 2: 20, 3: 17, 4: 6, 5: 147}\n",
    "rf_consistency = {1: 17, 2: 14, 3: 14, 4: 19, 5: 160}\n",
    "\n",
    "# Calculate consistency scores\n",
    "xgb_consistency_score = calculate_consistency_score(xgb_consistency)\n",
    "rf_consistency_score = calculate_consistency_score(rf_consistency)\n",
    "\n",
    "print(f\"XGBoost Consistency Score: {xgb_consistency_score:.4f}\")\n",
    "print(f\"RF Consistency Score: {rf_consistency_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
